# Руководство по настройке удаления сегментов сообщений в Apache Kafka

Для управления удалением сообщений в Kafka нужно учитывать несколько параметров, которые определяют, как долго сообщения хранятся и через какие интервалы времени сегменты файлов проверяются на возможность удаления. В этой документации мы рассмотрим настройку этих параметров, особенности поведения Kafka и процесс удаления сегментов.

Во второй части, будут описаны особенности установки переменных окружения в Bitnami Kafka.

1. Настройка интервала проверки сегментов на удаление

Открываем файл конфигурации *server.properties* Kafka и настраиваем параметр *log.retention.check.interval.ms*. Этот параметр отвечает за частоту, с которой специальный поток (LogCleaner) проверяет условия для удаления старых сообщений. По умолчанию значение составляет 5 минут (300000 миллисекунд), что подходит для production-систем, но может быть слишком долгим для тестовых окружений.

Чтобы сократить интервал проверки до 1 секунды, установите:
```sh
log.retention.check.interval.ms=1000
```

Так LogCleaner будет проверять данные раз в секунду и быстрее реагировать на изменения параметров хранения (retention). Сохраняем файл и перезапускаем контейнер с новой конфигурацией.

2. Настройка политики хранения сообщений в топиках

Теперь настроим параметры retention у конкретного топика (глобально, во второй части) и изменим значение *retention.ms*. Этот параметр определяет, как долго сообщения будут храниться в топике, после чего они могут быть удалены. Например, установив значение в 60 000 миллисекунд (1 минута), мы укажем Kafka удалять сообщения старше одной минуты:

```bash
kafka-configs.sh --alter --entity-type topics --entity-name <имя_топика> --add-config retention.ms=60000 --bootstrap-server localhost:9092
```

После применения этой настройки все сообщения старше 1 минуты будут помечены как старые и подлежащие удалению. Однако если продюсер будет отправлять сообщения чаще чем 1 сообщение в минуту, сегмент, содержащий эти сообщения, *не будет удален*, пока не выполнится **условие закрытия сегмента**.

3. Понимание работы сегментов в Kafka

Kafka хранит сообщения на диске в виде сегментов. Партиция топика состоит из набора файлов, называемых сегментами. Сообщения, отправленные продюсерами, сохраняются в открытый (или головной) сегмент партиции. По мере того как сообщения поступают в топик, Kafka проверяет условия для закрытия сегмента на основе заданных параметров. Когда сегмент закрыт (открыт новый), он становится иммутабельным, то есть данные в нём не изменяются.

LogCleaner в Kafka удаляет данные исключительно на уровне сегментов. То есть при удалении сообщений удаляется целый файл сегмента. Для того чтобы понять, можно ли удалить сегмент, LogCleaner выполняет следующие шаги:

  -  Находит максимальный таймстамп сообщения внутри сегмента.
  -  Находит разницу между этим таймстампом и текущим временем.
  -  Сравнивает полученную разницу с конфигурацией retention.ms.
  -  Если разница больше значения retention.ms, сегмент считается старым и подлежит удалению.

4. Важность правильного закрытия сегментов. 

Если сообщения отправляются в открытый сегмент партиции с высокой частотой, то таймстамп сообщений внутри сегмента будет постоянно обновляться. Это предотвращает удаление сегмента даже при настройке низкого *retention.ms*. Поэтому важно настроить параметры закрытия сегментов, такие как *segment.ms* и *segment.bytes*:

  -  segment.ms: Период времени, через который сегмент закрывается. По умолчанию — 1 неделя (604800000 миллисекунд).
  -  segment.bytes: Максимальный размер сегмента в байтах. По умолчанию — 1 ГБ (1073741824 байт).

Эти параметры работают в связке методом ИЛИ. Сегмент закрывается, если выполнено одно из двух условий: либо достигается максимальный размер сегмента, либо проходит заданное время с момента его создания.

Допустим, если *retention.ms* у нас выставлен в 10 минут. А сообщение поступает в топик каждую минуту. Разница во времени никогда не превысит это заданное значение, потому что мы постоянно дописываем сообщения. Если бы мы остановили продюсера и подождали 10 минут, то увидели бы, что данные удалены. Плюс, если бы текущий сегмент закрылся, то оказавшиеся в нем данные очень быстро удалились. 

Поэтому рекомендуется настроить параметр *segment.ms* на разумное значение (например, 5 минут) или уменьшить *segment.bytes*, чтобы сегменты закрывались раньше. Это позволит LogCleaner быстрее помечать сегменты как удаляемые.

Процесс идет таким образом: старые сегменты закрываются, новые открываются. Старые сегменты при этом помечаются как deleted, затем еще один бэкграунд тред полностью удаляет их с диска.

# Уточнение особенностей использования переменных окружения для конфигурации Kafka в Bitnami образах

При настройке Apache Kafka через переменные окружения в Docker Compose или Kubernetes, важно учитывать способ их применения в Bitnami образах. Bitnami Kafka использует механизм создания конфигурационных файлов на основе переменных окружения *при первом запуске* контейнера. Этот процесс влияет на поведение параметров конфигурации в последующих перезапусках. Рассмотрим эту особенность подробнее.

1. Пример настройки через переменные окружения

Для изменения настроек Kafka через Docker Compose или Kubernetes, обычно используются переменные окружения. Например:

```yaml
environment:
  - KAFKA_CFG_LOG_RETENTION_MS=60000                     # Период хранения сообщений - 1 минута
  - KAFKA_CFG_LOG_RETENTION_CHECK_INTERVAL_MS=1000       # Интервал проверки хранения - 1 секунда
  - KAFKA_CFG_LOG_SEGMENT_MS=300000                      # Время закрытия сегмента - 5 минут
  - KAFKA_CFG_LOG_SEGMENT_BYTES=10485760                 # Размер сегмента - 10 MB
```

Эти параметры позволяют гибко настраивать политику хранения и удаления сообщений.
Например, значение KAFKA_CFG_LOG_RETENTION_MS=60000 задаёт время хранения сообщений в 1 минуту, а KAFKA_CFG_LOG_SEGMENT_MS=300000 устанавливает период закрытия сегментов на 5 минут.

2. Поведение Bitnami Kafka при использовании переменных окружения

При первом запуске контейнера kafka с образа Bitnami, указанные переменные окружения записываются в основной конфигурационный файл /opt/bitnami/kafka/config/server.properties. Это происходит только один раз — во время начальной инициализации. Все последующие запуски контейнера используют этот уже созданный файл, не обращая внимания на изменения значений переменных окружения.

*Важно*: Простое изменение значения переменной, например:
```yaml
environment:
  - KAFKA_CFG_LOG_RETENTION_MS=3600000  # Новое значение периода хранения сообщений - 1 час
```
и перезапуск контейнера с помощью команды docker-compose up -d **не приведет к изменению конфигурации Kafka**. Контейнер продолжит использовать уже созданный файл server.properties с первоначальными значениями переменных.

3. Правильное применение новых значений переменных окружения

Чтобы изменения в конфигурации переменных окружения вступили в силу, необходимо:

  1) Удалить существующий конфигурационный файл server.properties
  2) Перезапустить контейнер

После этого, Kafka инициализирует конфигурацию заново, создавая файл server.properties с актуальными значениями переменных окружения.

4. Важные замечания

  -  Изменения конфигурации через переменные среды влияют только на создание нового конфигурационного файла.
  -  При обновлении переменных среды и перезапуске контейнера без удаления существующего server.properties изменений в конфигурации Kafka не произойдёт.
  -  Для production-систем такой способ изменения конфигурации не всегда удобен, так как удаление файла и пересоздание конфигурации требует остановки контейнера и временной недоступности Kafka.

### Альтернативные методы изменения конфигурации
  Если необходимо изменить параметры на работающем кластере Kafka без удаления файлов конфигурации, можно использовать команды kafka-configs.sh для изменения настроек в реальном времени:

    ```sh
    docker exec -it <имя_контейнера> kafka-configs.sh --alter --bootstrap-server localhost:9092 --entity-type brokers --entity-name <номер_брокера> --add-config log.retention.ms=3600000
    ```
  Этот способ применяет изменения динамически и не требует перезапуска брокеров, что удобно для production-систем. (В переменных еслтественно тоже нужно изменить)

5. Проверка новых настроек

После перезапуска контейнера с обновленной конфигурацией, убедитесь, что новые параметры успешно применены. Используйте команду kafka-configs.sh для описания параметров топика или сервера:

```bash
docker exec -it <имя_контейнера> kafka-configs.sh --describe --entity-type topics --bootstrap-server localhost:9092 --all
```
Или, если вы хотите проверить параметры конкретного топика:
```bash
docker exec -it <имя_контейнера> kafka-topics.sh --describe --topic <имя_топика> --bootstrap-server localhost:9092
```
